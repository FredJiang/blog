---
title: 梯度下降
date: 2017-07-27 07:20:10
tags: [machine learning]
---

<script type="text/javascript"
   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


参考 <http://blog.csdn.net/linvo/article/details/9919611?utm_source=tuicool> 里面的代码


<!--more-->

随机梯度下降

```python
# -*- coding:utf-8 -*-
"""
增量梯度下降
# 一般设置 x0 为 1
y = 1 + 0.5 * x
"""
import sys

# 训练数据集
# 自变量 x(x0, x1)
# 一般设置 x0 为 1
x = [(1, 1.15), (1, 1.9), (1, 3.06), (1, 4.66), (1, 6.84), (1, 7.95)]
# 假设函数 h(x) = theta0*x[0] + theta1*x[1]
# y为理想theta值下的真实函数值
y = [1.37, 2.4, 3.02, 3.06, 4.22, 5.42]

# 两种终止条件
loop_max = 10000 # 最大迭代次数
epsilon = 0.0001 # 收敛

alpha = 0.005 # 步长
diff = 0 # 每一次试验时当前值与理想值的差距
error0 = 0 # 上一次目标函数值之和
error1 = 0 # 当前次目标函数值之和
m = len(x) # 训练数据条数

# init the parameters to zero
theta = [0,0]

count = 0
finish = 0

while count < loop_max:
    count += 1

    # 遍历训练数据集，不断更新 theta 值
    for i in range(m):
        # 训练集代入，计算假设函数值 h(x) 与真实值 y 的误差值
        diff = (theta[0] + theta[1] * x[i][1]) - y[i]

        # 求参数 theta，增量梯度下降算法，每次只使用一组训练数据
        theta[0] = theta[0] - alpha * diff * x[i][0]
        theta[1] = theta[1] - alpha * diff * x[i][1]
    # 此时已经遍历了一遍训练集，求出了此时的 theta 值
    # 判断是否已收敛

    print '%.10f %.10f %.10f %.10f'%(theta[0], theta[1], abs(theta[0] - error0), abs(theta[1] - error1))

    if abs(theta[0]-error0) < epsilon and abs(theta[1]-error1) < epsilon:
        print 'theta:[%f, %f]'%(theta[0],theta[1])
        finish = 1
    else:
        error0,error1 = theta
    if finish:
        break

print 'FINISH count:%s' % count
```


先把数据画上




```
x = [
1.15
1.9
3.06
4.66
6.84
7.95
];
y = [
1.37
2.4
3.02
3.06
4.22
5.42
];
clf
scatter(x, y);
```

{% asset_img "scatter_data.png" "" %}


运行代码 `python demo.py`

得到如下预测结果

```
theta:[1.066522, 0.515434]
FINISH count:564
```


画出 hypothesis 函数

```
x = [
1.15
1.9
3.06
4.66
6.84
7.95
];
y = [
1.37
2.4
3.02
3.06
4.22
5.42
];
y1 = 1.066522 + x1 * 0.515434;
x1 = [0:0.01:8];
clf
hold on;
scatter(x, y);
plot(x1, y1);
hold off;
```



{% asset_img "hypothesis.png" "" %}





批量梯度下降

$$
\begin{align*} 
& \text{repeat} \{ \\
& \ \ \ \ \theta_j := \theta_j - \alpha \frac{1}{m} \sum_{i=1}^{m} (h_\theta (x^{(i)}) - y^{(i)}) \cdot x_j^{(i)} \\
& \} \\
\end{align*}
$$


随机批量梯度下降
$$
\begin{align*} 
& \text{for i = 1 to m} \{ \\
& \ \ \ \ \theta_j := \theta_j - \alpha (h_\theta (x^{(i)}) - y^{(i)}) \cdot x_j^{(i)} \\
& \} \\
\end{align*}
$$




python demo.py > dataFromFile.bat



根据数据


```
[fred@pwrd-net-10-8-6-216 ml]$ head dataFromFile.bat
0.0797673928 0.3825385016 0.0797673928 0.3825385016
0.1175986506 0.5435446264 0.0378312578 0.1610061248
0.1376766195 0.6109370608 0.0200779689 0.0673924344
0.1502211046 0.6387736614 0.0125444851 0.0278366005
0.1595511875 0.6498990114 0.0093300829 0.0111253501
0.1674923271 0.6539670980 0.0079411396 0.0040680866
0.1748161862 0.6550576184 0.0073238591 0.0010905204
0.1818490963 0.6548945989 0.0070329101 0.0001630196
0.1887291917 0.6542065694 0.0068800954 0.0006880294
0.1955150738 0.6533013680 0.0067858822 0.0009052015
[fred@pwrd-net-10-8-6-216 ml]$ tail dataFromFile.bat
1.0655982381 0.5155804548 0.0001066471 0.0000168959
1.0657040765 0.5155636871 0.0001058384 0.0000167677
1.0658091124 0.5155470465 0.0001050358 0.0000166406
1.0659133517 0.5155305321 0.0001042394 0.0000165144
1.0660168006 0.5155141429 0.0001034489 0.0000163892
1.0661194651 0.5154978780 0.0001026645 0.0000162649
1.0662213511 0.5154817365 0.0001018860 0.0000161416
1.0663224644 0.5154657173 0.0001011134 0.0000160192
1.0664228111 0.5154498197 0.0001003466 0.0000158977
1.0665223968 0.5154340425 0.0000995857 0.0000157771
```

得到 `$ \theta_0 $` 和 `$ \theta_1 $` 的趋势图


```
clf; clear; close all; clc;
dataFromFile = load('dataFromFile.bat');
rowCount = rows(dataFromFile);
plot3([0:1:rowCount-1], zeros(1, rowCount), dataFromFile(:,1), '-g');
hold on;
plot3(zeros(1, rowCount), [0:1:rowCount-1], dataFromFile(:,2), '-r');
hold off;
xlabel("theta0 index");
ylabel("theta1 index");
legend('theta0', 'theta1');
```


{% asset_img "theta.png" "" %}






这里假设 `$ \theta_0 $` 为 1.066522，来看下 `$ \theta_1 $` 和 `$ J(\theta) $` 的关系


cost function

$$
\begin{align*} 
J(\theta_0, \theta_1) 
& = \frac{1}{2m} \sum_{i=1}^m {(h_\theta(x^{(i)}) - y^{(i)} ) }^2 \\
& = \frac{1}{2m} \sum_{i=1}^m {(\theta_0 + \theta_1x^{(i)} - y^{(i)} ) }^2 \\
& = \frac{1}{2m} \sum_{i=1}^m {(1.066522 + \theta_1x^{(i)} - y^{(i)} ) }^2
\end{align*} 
$$



```
clf; clear; close all; clc;
x = [
1.15
1.9
3.06
4.66
6.84
7.95
];
y = [
1.37
2.4
3.02
3.06
4.22
5.42
];
dataFromFile = load('dataFromFile.bat');
theta1 = dataFromFile(:,2);
j_theta = 1 / 2 * 6 * ( 
power(1.066522 + theta1 * x(1) - y(1), 2) +
power(1.066522 + theta1 * x(2) - y(2), 2) +
power(1.066522 + theta1 * x(3) - y(3), 2) +
power(1.066522 + theta1 * x(4) - y(4), 2) +
power(1.066522 + theta1 * x(5) - y(5), 2) +
power(1.066522 + theta1 * x(6) - y(6), 2)
);
plot(theta1, j_theta);
```

{% asset_img "jtheta_theta1.png" "" %}


如图上图，`$ \theta_1 $` 在 0.55 的附近位置时，往右走了，如果能往左的话，能更快地找到最小点

`$ \theta_1 $` 趋势图

```
clf; clear; close all; clc;
dataFromFile = load('dataFromFile.bat');
rowCount = rows(dataFromFile);
plot([0:1:rowCount-1], dataFromFile(:,2), '-r');
```

{% asset_img "theta1_trend.png" "" %}





梯度下降






```python
# -*- coding:utf-8 -*-
"""
增量梯度下降
# 一般设置 x0 为 1
y = 1 + 0.5 * x
"""
import sys

# 训练数据集
# 自变量 x(x0, x1)
# 一般设置 x0 为 1
x = [(1, 1.15), (1, 1.9), (1, 3.06), (1, 4.66), (1, 6.84), (1, 7.95)]
# 假设函数 h(x) = theta0*x[0] + theta1*x[1]
# y为理想theta值下的真实函数值
y = [1.37, 2.4, 3.02, 3.06, 4.22, 5.42]

# 两种终止条件
loop_max = 10000 # 最大迭代次数
epsilon = 0.0001 # 收敛

alpha = 0.005 # 步长
diff = 0 # 每一次试验时当前值与理想值的差距
error0 = 0 # 上一次目标函数值之和
error1 = 0 # 当前次目标函数值之和
m = len(x) # 训练数据条数

# init the parameters to zero
theta = [0,0]

count = 0
finish = 0

while count < loop_max:
    count += 1
    diff = 0

    for i in range(m):
        diff += (theta[0] + theta[1] * x[i][1]) - y[i]

    theta[0] = theta[0] - alpha * diff * x[i][0]
    theta[1] = theta[1] - alpha * diff * x[i][1]

    print '%.10f %.10f %.10f %.10f'%(theta[0], theta[1], abs(theta[0] - error0), abs(theta[1] - error1))

    if abs(theta[0]-error0) < epsilon and abs(theta[1]-error1) < epsilon:
        print 'theta:[%f, %f]'%(theta[0],theta[1])
        finish = 1
    else:
        error0,error1 = theta
    if finish:
        break

print 'FINISH count:%s' % count
```


`python demo1.py > dataFromFile1.bat`


得到如下预测结果

```
theta:[0.093163, 0.740647]
FINISH count:4
```




画出 hypothesis 函数

```
xData = [
1.15
1.9
3.06
4.66
6.84
7.95
];
yData = [
1.37
2.4
3.02
3.06
4.22
5.42
];
xRange = [0:0.01:8];
yNormal = 0.093163 + xRange * 0.740647;
yRandom = 1.066522 + xRange * 0.515434;
clf
hold on;
plot(xRange, yNormal);
plot(xRange, yRandom);
legend('normal', 'random');
scatter(xData, yData);
hold off;
```



{% asset_img "mixer.png" "" %}


```
clf; clear; close all; clc;
x = [
1.15
1.9
3.06
4.66
6.84
7.95
];
y = [
1.37
2.4
3.02
3.06
4.22
5.42
];
dataFromFile = load('dataFromFile.bat');
theta1 = dataFromFile(:,2);
j_theta = 1 / 2 * 6 * ( 
power(0.093163 + theta1 * x(1) - y(1), 2) +
power(0.093163 + theta1 * x(2) - y(2), 2) +
power(0.093163 + theta1 * x(3) - y(3), 2) +
power(0.093163 + theta1 * x(4) - y(4), 2) +
power(0.093163 + theta1 * x(5) - y(5), 2) +
power(0.093163 + theta1 * x(6) - y(6), 2)
);
plot(theta1, j_theta);

```




{% asset_img "theta_1_jtheta.png" "" %}


```
xData = [
1.15
1.9
3.06
4.66
6.84
7.95
];
yData = [
1.37
2.4
3.02
3.06
4.22
5.42
];
theta_0_random = 1.066522;
theta_1_random = 0.515434;
J_theta_random = 0;
theta_0_normal = 0.093163;
theta_1_normal = 0.740647;
J_theta_normal = 0;
for i = 1:rows(xData)
          printf("power(theta_0_random + theta_1_random * xData(i, 1) - yData(i, 1), 2) = %d\n",
                  power(theta_0_random + theta_1_random * xData(i, 1) - yData(i, 1), 2));
J_theta_random += power(theta_0_random + theta_1_random * xData(i, 1) - yData(i, 1), 2);
endfor
printf("J_theta_random = %d\n", J_theta_random);
for i = 1:rows(xData)
          printf("power(theta_0_normal + theta_1_normal * xData(i, 1) - yData(i, 1), 2) = %d\n",
                  power(theta_0_normal + theta_1_normal * xData(i, 1) - yData(i, 1), 2));
J_theta_normal += power(theta_0_normal + theta_1_normal * xData(i, 1) - yData(i, 1), 2);
endfor
printf("J_theta_normal = %d\n", J_theta_normal);
```


得出

* J_theta_random = 0.721367
* J_theta_normal = 2.85816

